---
title: "ITS workflow-Network Analysis"
author: "Sarah Daly"
date: '2024-07-30'
output:
  html_document: default
  word_document: default
editor_options:
  chunk_output_type: console
---

Input:
OTU table (.qza), unfiltered taxonomy table (.qza), rooted photogenic tree (.qza), metadata file (.txt)
Output
.csv and .tif 

All Sequencing Samples Summer Fall Winter Spring

Results focus on Fan/Walls/doors/floors 

#Set Working Directory
```{r}
setwd("C:/Users/dalys/Box/Microbial Food Safety & Spoilage Lab/Lab Members/Sarah Daly/ITS Methods Project/Github upload/Network_analysis")

list.files()
```

#Load Packages
There will be errors/warnings when you load packages but most you can ignore 
```{r}
library(scales)

library(DECIPHER) # This package will help in importing, maintaining, analyzing, manipulating, and exporting a massive amount of sequences.

library(ape) # Analyses of Phylogenetics and Evolution package. Required for tree calculations to be used with phyloseq

library(DESeq2) # This package will help analyze "differential expression" in the microbiota alongside phyloseq

library(ggplot2) # Graphing package used in phyloseq. To edit the default setting of a plot, you need to use functions in this package.

library(phyloseq) # The phyloseq package seeks to address issues with multiple microbiome analysis packages by providing a set of functions that internally manage the organizing, linking, storing, and analyzing of phylogenetic sequencing data. In general, this package is used for UniFrac analyses.

library(plotly) # A package to create interactive web graphics of use in 3D plots

library(vegan) # The vegan package provides tools for descriptive community ecology. It has most basic functions of diversity analysis, community ordination and dissimilarity analysis. In general, this package is used for Bray-Curtis and Jaccard analyses.

library(tidyverse) # This package is designed to make it easy to install and load multiple 'tidyverse' packages in a single step

library(adespatial) # Tools for the multiscale spatial analysis of multivariate data

library(devtools) # Make package development easier by providing R functions that simplify and expedite common tasks

library(qiime2R) # A package for importing qiime artifacts into an R session

library(microbiome) # Data analysis and visualization

library(microbiomeSeq) # Data analysis and visualization

library("pander") # provide a minimal and easy tool for rendering R objects into Pandoc's markdown

library(ranacapa) # Data analysis 

library(grid) # support data visualization

library(gridExtra)  # support data visualization

library(knitr) # Provides a general-purpose tool for dynamic report generation in R using Literate Programming techniques.

library(png) # Figure download

library("ggdendro") #set of tools for dendrograms and tree plots using 'ggplot2'

library(ggpubr) # publication quality figures, based on ggplot2

library(RColorBrewer) # nice color options

library(microbiomeutilities) # some utility tools 

library(broom) #tidy anova tables 
library(hrbrthemes)
library(gcookbook)
library(tidyverse)
library(dplyr)
```

#Create a vector of colors for plotting
```{r}
nice_colors = c("#999999", "#E69F00", "#56B4E9","#e98756","firebrick3","#5800e6", "#CDDC49", "#C475D3", 
                "#E94B30", "#233F57", "#FEE659", "#A1CFDD", "#F4755E", "#D6F6F7","blueviolet", "#6898BF","cornsilk",  "tan3", "violetred4", "seashell3", "forestgreen", "grey60", "hotpink", "darkgreen", "dodgerblue3", "gold", "springgreen", "slateblue2", "darkolivegreen", "deeppink4", "gray16", "white", "yellow", "red", "tan", "slategray3", "wheat", "thistle4", "peachpuff", "plum", "orangered", "mediumseagreen", "hotpink4", "goldenrod3", "ivory", "darkturquoise", "lightgoldenrod", "violet", "firebrick", "mistyrose2", "brown", "rosybrown", "royalblue", "orange", "blue", "hotpink2", "tan4", "plum2", "grey40", "firebrick4", "violet", "brown4", "ivory2", "seashell4")
                
#ASsign colors to factors
color_factor<- c("Summer" = "firebrick",
"Fall" =          "gold"  ,
"Winter" =            "dodgerblue" ,  
"Spring" =          "plum" ,
 "Raw" =           "coral"  ,     
 "Filling" =           "darkseagreen",
 "Post-Pasteurization" = "darkorchid",
"Post-Pasteurization " = "darkorchid",
"Warehouse"= "burlywood",
"Wall/Ceiling" = "mediumaquamarine",
"Door" = "grey",
"Fan/Vent" = "lightgoldenrod",
"Floor" = "hotpink",
"Floor Object" = "hotpink")
 
```


#Load Data and Convert to Phyloseq Object
```{r}
#Convert qiime artifacts directly to phyloseq
#phyloseq provides a set of classes and tools to facilitate the import, storage, analysis, and graphical display of microbiome census data.

#List files
list.files()

#Importing OTU/ASV table
ASVS <- read_qza("q20/otu-table-dn-99-SFWS-q20.qza")   #Qiime output ASV file after filtering
dim(ASVS$data)

# Importing phylogenic tree
tree <- read_qza("q20/rooted_tree.qza")  #Qiime output file
tree$data

# Importing taxonomy assignment 
taxonomy <- read_qza("q20/unite-dyn-11-22-ITS-taxonomy-otu.qza")  #Qiime output file

#Process taxonomy file more 
#get taxonomy names
tax_strings<- strsplit(as.character(taxonomy$data$Taxon), ";")
head(tax_strings)

#some strings are missing levels (blanks) and the dataframe will not bind
x = 1
y = 1

blanks <- c("k__","p__", "c__", "o__","f__", "g__", "s__")

num_taxa = length(tax_strings)  #number of taxa
num_taxa  #shoudl match dim OTUs$data

for (item in tax_strings){
  
  t = length(tax_strings[[x]]) #get list item length
  
if (t < 7)  {  #if less than 7 elements in each list item
  #print(t)
  y=1
  #print(taxa)
  while (y <= 7){  #loop through each item in item 
    if (is.na(tax_strings[[x]][y])){
      print('needs')
      tax_strings[[x]][y] = blanks[y]  #replace blank space with corr level character
      y=y+1
      }
      else(y=y+1)
    }
x = x+1
}
  else (x = x+ 1)
}

#convert to dataframe
tax_table<-as.data.frame(tax_strings)
dim(tax_table)
#Trasnpose table
tax_table<-t(tax_table)
head(tax_table)

#Add level labels
#Add oto/asv info to tax table
rownames(tax_table) <- taxonomy$data$Feature.ID
colnames(tax_table) <- c("Kingdom","Phylum","Class","Order","Family","Genus","Species")
head(tax_table)
#Inspect table 
write.csv(tax_table, "merged_tax_table.csv")

#################Creating phyloseq object#######################################

#Note, phyloseq uses the term "OTU" loosely and since we fed it an ASV table, it is an ASV table
OTU = otu_table(as.matrix(ASVS$data), taxa_are_rows = T)
#Transpose OtU table
otu_table(OTU)<-t(otu_table(OTU))  #may need to do this again

TAX = tax_table(as.matrix(tax_table))
dim(TAX)
dim(taxa_names(OTU))
head(TAX)

# Importing metadata
metadata <- read.table("q20/Metadata_ITS2.txt", sep='\t', header=T, row.names=1, comment="")
head(metadata)
dim(metadata)
length(sample_names(OTU))
SAMPLE = sample_data(metadata)

#phylogentic tree
TREE = tree$data

#Inspect files for troubleshooting 
write.csv(SAMPLE, "phyloseq SAMPLE input.csv")
write.csv(TAX, "phyloseq TAX input.csv")
write.csv(OTU, "phyloseq OTU input.csv")

# merge the data
ps <- phyloseq(OTU, TAX, SAMPLE,TREE)
#contains OTU table, taxonomy table, sample data, and phy tree
#check that dimensions are consistent (same number taxa setwd("..")
#getwd()between OTU, tax_table)
ps
#######################Summary stats from phyloseq object########################
#Summarizing the phyloseq object to check for feature of data
# check for features of data  
summarize_phyloseq(ps)
print_ps(ps)
head(sample_data(ps))


unique((sample_data(ps))$Freq_cat)

sample_data(ps)$Frequency<-replace(sample_data(ps)$Freq_cat, sample_data(ps)$Freq_cat=="None", "None/as needed")

sample_data(ps)$Frequency<-replace(sample_data(ps)$Freq_cat, sample_data(ps)$Freq_cat=="As needed", "None/as needed")

unique((sample_data(ps))$Freq_cat)


```

#Filter Phyloseq Object for missing or Low Abundance Genera
https://github.com/joey711/phyloseq/issues/1483 
```{r}
#####################################################
# Creating a table for number of features for each phyla
table(tax_table(ps)[, "Genus"], exclude = NULL)

# Removing the NAs and uncharacterized Phylums
ps0 <- subset_taxa(ps, !is.na(Genus) & !Genus %in% c("", "g__"))#Remove unidentified genera

# Summary Before and After
ps
ps0

# Compute prevalence of each feature, store as data.frame
prevdf = apply(X = otu_table(ps0),
               MARGIN = ifelse(taxa_are_rows(ps0), yes = 1, no = 2),
               FUN = function(x){sum(x > 0)})

# Add taxonomy and total read counts to this data.frame
prevdf = data.frame(Prevalence = prevdf,
                    TotalAbundance = taxa_sums(ps0),
                    tax_table(ps0))
# Viewing
head(prevdf)
# Computing average and total prevalence
temp_df <- plyr::ddply(prevdf, "Genus", function(df1){cbind(mean(df1$Prevalence),sum(df1$Prevalence))})

newdata<- temp_df
colnames(newdata) <- c("Genus", "mean","sum_total")
head(newdata)

newdata<- newdata%>% arrange(desc(sum_total))
head(newdata)

write.csv(newdata, "Prevlance_Genus.csv")

# Vector to be removed
filterGenus <- temp_df[temp_df$`2` < 10,]$Genus  #Can change this number should be at least greater than 2

# Filter entries with unidentified Phylum.
ps1 = subset_taxa(ps0, !Genus %in% filterGenus)

# Summary
ps
ps0
ps1

```

#Filter samples By categories 
```{r}
#GEt samples to keep for Built Environment (n=119)
keep<- read.csv("keep.csv")
ps_be<- subset_samples(ps1, samples %in% keep$Sample.ID)
ps_be
capture.output((ps_be), file = "Phyloseq_Object_BE.txt")


#Filter by Facility 
ps_be_NL<- subset_samples(ps_be, Facility=="Facility3")
ps_be_NL
ps_be_B<- subset_samples(ps_be, Facility=="Facility2")
ps_be_B
ps_be_WS<- subset_samples(ps_be, Facility=="Facility1")
ps_be_WS

#Room
ps_PP<- subset_samples(ps_be, RoomType %in% c("Post-Pasteurization "))
ps_PP
ps_Ware<- subset_samples(ps_be, RoomType %in% c("Warehouse"))
ps_Ware
ps_Raw<- subset_samples(ps_be, RoomType %in% c("Raw"))
ps_Raw
ps_Filling<- subset_samples(ps_be, RoomType %in% c("Filling"))
ps_Filling


#Season
ps_Fall<- subset_samples(ps_be, Season=="Fall")
ps_Fall
ps_Spring<- subset_samples(ps_be, Season=="Spring")
ps_Spring
ps_Winter<- subset_samples(ps_be, Season=="Winter")
ps_Winter
ps_Summer<- subset_samples(ps_be, Season=="Summer")
ps_Summer

#oBJECT
ps_be_fan<- subset_samples(ps_be, Object =="Fan/Vent")
ps_be_fan
ps_be_wall<- subset_samples(ps_be, Object =="Wall/Ceiling")
ps_be_wall
ps_be_floor<- subset_samples(ps_be, Object =="Floor Object")
ps_be_floor
ps_be_door<- subset_samples(ps_be, Object =="Door")
ps_be_door

```

#Microbiome Network
```{r}
# convert to relative abundance
library(igraph)
setwd(("./Network_area")) 

######################Function#########################
network_taxa <- function(ps_object, name){
#Set seed for repdocucability
set.seed(99)
physeq_rel <- ps_object

#(Optional). Default 0.4. The maximum ecological distance (as defined by distance) allowed between two samples to still consider them “connected” by an edge in the graphical model
ig <- make_network(physeq_rel, dist.fun="bray", max.dist=0.8)
p2<- plot_network(ig, physeq_rel, color="RoomType", line_weight=1.5, label=NULL, point_size=12)+scale_colour_manual(values=color_factor)
write.csv (p2$data, paste(name,"Network Distance Bray-Curtis.csv"))


#Get info about network
print(neighborhood(ig))

#Diameter = lenght of longest connection 
diameter_ig<- diameter(ig)
#Number of nodes
numodes<- length(degree(ig))
#No edges
numdeg <- ecount(ig)

#Number of points connected to each vertex
degree(ig)
avgdeg <- numdeg / numodes

#Get centrality-The higher the network centralization, the more connected the network is
cent<- centralization.degree(ig)$centralization

#No. clusters
no_clusters<- clusters(ig)$no

vector= c(paste("diameter=", diameter_ig), paste("no. clusters", no_clusters), paste("centrality=", cent),paste("no nodes=", numodes), paste("no degrees=", numdeg), paste("Avg deg=", round(avgdeg,4)))
print(vector)

capture.output(vector , file = paste(name,"Network.txt"))


#Export plot to .tif file 
tiff(paste(name,"Bray-curtis Network.tif", sep=" "), res=300, compression = "lzw", height=9, width=9, units="in")
print(p2)
dev.off()

#Photo edit PDF in Inkscape 
pdf(paste(name,"Bray-curtis Network.pdf", sep=" "), height = 9, width = 9)
print(p2)
dev.off()

return(ig)
}
#########################################################
net_ig_NL<- network_taxa(ps_be_NL, "Built Environment_NL")
net_ig_B<- network_taxa(ps_be_B, "Built Environment_B")
net_ig_WS<- network_taxa(ps_be_WS, "Built Environment_WS")

```
